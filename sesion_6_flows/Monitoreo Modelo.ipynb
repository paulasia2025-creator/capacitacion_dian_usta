{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f15ad06-55fe-4592-aaff-949a859af501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Celda 1: Configurar el contexto\n",
    "USE CATALOG sesion_5;\n",
    "USE SCHEMA gold;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8df30694-0889-460c-a26e-50093dbe67af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Celda 2: Crear la tabla de características del cliente (RFM)\n",
    "-- Esta tabla será la entrada para nuestro modelo de K-Means.\n",
    "CREATE OR REPLACE TABLE customer_features_gold AS\n",
    "WITH\n",
    "  -- Paso 1: Calcular la fecha de la última compra en todo el dataset para tener un punto de referencia consistente para la recencia.\n",
    "  max_order_date AS (\n",
    "    SELECT MAX(fecha_pedido) AS max_date FROM silver.fact_pedidos\n",
    "  ),\n",
    "  \n",
    "  -- Paso 2: Calcular las métricas base de RFM por cliente único.\n",
    "  rfm_metrics AS (\n",
    "    SELECT\n",
    "      c.customer_unique_id,\n",
    "      -- Recencia: ¿Qué tan recientemente compró el cliente? (Menor es mejor)\n",
    "      DATEDIFF((SELECT max_date FROM max_order_date), MAX(fo.fecha_pedido)) AS recency,\n",
    "      -- Frecuencia: ¿Con qué frecuencia compra el cliente?\n",
    "      COUNT(DISTINCT fo.order_id) AS frequency,\n",
    "      -- Monetario: ¿Cuánto gasta el cliente?\n",
    "      SUM(fo.valor_pago) AS monetary\n",
    "    FROM\n",
    "      silver.fact_pedidos fo\n",
    "    JOIN\n",
    "      silver.dim_clientes_sql c ON fo.customer_id = c.customer_id\n",
    "    WHERE fo.order_status = 'delivered' -- Solo se consideran pedidos completados.\n",
    "    GROUP BY\n",
    "      c.customer_unique_id\n",
    "  )\n",
    "\n",
    "-- Paso 3: Seleccionar las características finales para la tabla Gold.\n",
    "SELECT\n",
    "  customer_unique_id,\n",
    "  recency,\n",
    "  frequency,\n",
    "  monetary\n",
    "FROM rfm_metrics;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aea6cfc-f7d7-4d4a-a2e8-5fbb45329c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Taller de Machine Learning: Segmentación de Clientes con Sklearn y MLflow\n",
    "\n",
    "# ==============================================================================\n",
    "# Celda 1: Importar las librerías necesarias\n",
    "# ==============================================================================\n",
    "# MLflow para el seguimiento de experimentos.\n",
    "import mlflow\n",
    "\n",
    "# Pandas para la manipulación de datos, que es el formato que prefiere scikit-learn.\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-learn para el preprocesamiento y el modelo de clustering.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Se necesita la sesión de Spark para obtener el nombre de usuario actual.\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3cda90b-99ec-47e9-b0e5-dec99dabde53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Celda 2: Cargar los datos de características desde la capa Gold\n",
    "# ==============================================================================\n",
    "# Se cargan los datos de la tabla Gold que se preparó en el notebook anterior.\n",
    "# Se convierten a un DataFrame de Pandas para poder usarlos con scikit-learn.\n",
    "print(\"Cargando datos desde sesion_5.gold.customer_features_gold...\")\n",
    "features_df = spark.table(\"sesion_5.gold.customer_features_gold\").toPandas()\n",
    "\n",
    "# Se establece el 'customer_unique_id' como el índice para facilitar la unión de los resultados más tarde.\n",
    "features_df.set_index(\"customer_unique_id\", inplace=True)\n",
    "\n",
    "print(f\"Se cargaron {len(features_df)} registros de clientes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc1356d7-b1c4-48b7-972b-34a77e21b4e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Celda 3: Preparar los datos para el modelo\n",
    "# ==============================================================================\n",
    "# K-Means es sensible a la escala de las características. Por ejemplo, 'monetary'\n",
    "# tendrá valores mucho más grandes que 'frequency'. El escalado asegura que\n",
    "# todas las características contribuyan por igual al cálculo de la distancia.\n",
    "\n",
    "print(\"Escalando características (Recencia, Frecuencia, Monetario)...\")\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82cbc55c-3d8e-4df8-b5ce-8abd6e4614a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Celda 4: Configurar y ejecutar el experimento de MLflow\n",
    "# ==============================================================================\n",
    "# Se obtiene el nombre de usuario actual de forma programática para crear una ruta de experimento única y válida.\n",
    "# Esto soluciona el error 'RESOURCE_DOES_NOT_EXIST' al asegurar que MLflow siempre tenga una ruta válida para guardar el experimento.\n",
    "user_email = spark.sql(\"SELECT current_user()\").first()[0]\n",
    "experiment_path = f\"/Users/{user_email}/customer_segmentation_sklearn\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "print(f\"Experimento de MLflow configurado en: {experiment_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b72b9b8f-958b-46fb-9ad9-51a9ebfe637f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Se inicia una nueva ejecución (run) dentro del experimento.\n",
    "# Todo lo que se registre (parámetros, métricas, modelos) quedará asociado a esta ejecución.\n",
    "with mlflow.start_run() as run:\n",
    "    # --- Habilitar el autologging para scikit-learn ---\n",
    "    # Esta es la magia de MLflow. Registrará automáticamente los parámetros del modelo,\n",
    "    # las métricas de entrenamiento y el modelo final sin necesidad de llamadas explícitas.\n",
    "    mlflow.autolog()\n",
    "\n",
    "    # NOTA SOBRE EL WARNING: El warning \"Training metrics will not be recorded because training labels were not specified\"\n",
    "    # es esperado. K-Means es un algoritmo de clustering (no supervisado) y no tiene \"etiquetas\" (labels) de entrenamiento.\n",
    "    # MLflow autolog() está optimizado para modelos supervisados, pero aún así registrará los parámetros y el modelo correctamente.\n",
    "\n",
    "    # --- Definir y entrenar el modelo ---\n",
    "    # A diferencia de la regresión, el clustering es un aprendizaje no supervisado.\n",
    "    # No hay un \"y_test\" para comparar. El objetivo es encontrar patrones en los datos,\n",
    "    # por lo que se entrena con todo el conjunto de datos.\n",
    "    num_clusters = 4 # Se puede experimentar con este valor.\n",
    "    \n",
    "    print(f\"Entrenando modelo K-Means con k={num_clusters}...\")\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "    kmeans.fit(features_scaled)\n",
    "\n",
    "    # --- Evaluar el modelo ---\n",
    "    # Aunque autolog() podría registrar algunas métricas, la puntuación de silueta\n",
    "    # es una métrica de evaluación clave para clustering que se debe calcular explícitamente.\n",
    "    # Mide qué tan similares son los puntos dentro de un clúster en comparación con otros clústeres.\n",
    "    # Un valor más cercano a 1 es mejor.\n",
    "    silhouette = silhouette_score(features_scaled, kmeans.labels_)\n",
    "    mlflow.log_metric(\"silhouette_score\", silhouette)\n",
    "    \n",
    "    print(f\"Modelo entrenado. Puntuación de Silueta: {silhouette:.3f}\")\n",
    "    \n",
    "    # Se guardan las predicciones (los segmentos de clientes) en el DataFrame original.\n",
    "    features_df['segment'] = kmeans.labels_\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Ejecución de MLflow completada. ID de la ejecución: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2bbfc10-0e69-489e-be93-54281b2b2d38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Celda 5: Guardar los resultados de la segmentación en una tabla Gold\n",
    "# ==============================================================================\n",
    "# Finalmente, se guardan los resultados para que el equipo de negocio pueda utilizarlos.\n",
    "# Se convierte el DataFrame de Pandas de nuevo a un DataFrame de Spark para guardarlo como tabla Delta.\n",
    "print(\"Guardando los segmentos de clientes en la tabla gold...\")\n",
    "results_spark_df = spark.createDataFrame(features_df.reset_index())\n",
    "\n",
    "results_spark_df.select(\"customer_unique_id\", \"segment\") \\\n",
    "    .write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"sesion_5.gold.customer_segments_gold\")\n",
    "\n",
    "print(\"¡Proceso completado! La tabla 'customer_segments_gold' ha sido creada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24f999ed-89e5-4daa-8cda-5a57989152a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Celda 6: Revisión de los resultados\n",
    "# ==============================================================================\n",
    "# Se muestra una vista previa de los segmentos asignados.\n",
    "display(results_spark_df)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5869184944042272,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Monitoreo Modelo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
